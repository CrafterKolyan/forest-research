{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./Ensemble')\n",
    "import bz2\n",
    "import os\n",
    "import urllib\n",
    "import MyEnsemble\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra functionallity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warm_predict(model, X, proba = False):\n",
    "    res = []\n",
    "    if isinstance(model, MyEnsemble.MyEnsemble):\n",
    "        res = model.get_each_tree_votes(X)\n",
    "        if proba:\n",
    "            res = res\n",
    "        else:\n",
    "            res = res.argmax(-1)\n",
    "        return res\n",
    "    \n",
    "    else:\n",
    "        for i, est in enumerate(model.estimators_):\n",
    "            if proba:\n",
    "                res.append(est.predict_proba(X))\n",
    "            else: \n",
    "                res.append(est.predict(X))\n",
    "        res = np.array(res)\n",
    "        return res\n",
    "\n",
    "def fpt(model, X, y):\n",
    "    res = model.predict(X)\n",
    "    print('acc: ', accuracy_score(y, res))\n",
    "    \n",
    "def get_my_params(model, num_classes, warm_start, max_depth, bootstrap_seed):\n",
    "    kwargs = {}\n",
    "    kwargs['reg_param'] = model.reg_param\n",
    "    kwargs['lr'] = model.lr \n",
    "    kwargs['num_trees'] = model.num_trees\n",
    "    kwargs['num_classes'] = num_classes\n",
    "    kwargs['warm_start'] = warm_start\n",
    "    kwargs['max_depth'] = max_depth\n",
    "    kwargs['bootstrap_seed'] = bootstrap_seed\n",
    "    return kwargs\n",
    "    \n",
    "def dump_info(nm, model, X, num_classes = None,\n",
    "              warm_start = None, max_depth = None, bootstrap_seed = None):\n",
    "    d = {}\n",
    "    d['labels'] = model.predict(X)\n",
    "    d['proba'] = model.predict_proba(X)\n",
    "    d['probs'] = warm_predict(model, X, proba = True)\n",
    "    if isinstance(model, MyEnsemble.MyEnsemble):\n",
    "        d['params'] =  get_my_params(model, num_classes, warm_start, max_depth, bootstrap_seed)\n",
    "    else:\n",
    "        d['params'] = model.get_params()\n",
    "    \n",
    "    path = './ModelsResults/'\n",
    "    with bz2.BZ2File(path+nm+'.pbz2', 'w') as f:\n",
    "        pk.dump(d, f)\n",
    "    \n",
    "def load_info(nm):\n",
    "    path = './ModelsResults/'\n",
    "    with bz2.BZ2File(path+nm+'.pbz2', 'r') as f:\n",
    "        d = pk.load(f)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./data/X.pk') and os.path.exists('./data/y.pk'):\n",
    "    X = np.load('./data/X.pk')\n",
    "    y = np.load('./data/y.pk')\n",
    "\n",
    "else:\n",
    "    link = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data-numeric\"\n",
    "    !mkdir ./data/\n",
    "    with urllib.request.urlopen(link) as f, open(\"./data/X.pk\", \"wb\"), open(\"./data/y.pk\", \"wb\"):\n",
    "        res = f.readlines()\n",
    "        for i, bs in enumerate(res):\n",
    "            res[i] = [int(el) for el in bs.decode(\"utf-8\").split(\" \") if not el in {'', ' ', '\\n'}]\n",
    "        res = np.array(res)\n",
    "    X, y = res[:, :-1], res[:, -1] - 1\n",
    "    X.dump(\"./data/X.pk\")\n",
    "    y.dump(\"./data/y.pk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10 parts split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = 0.5\n",
    "splits = []\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5,\n",
    "    random_state=42)\n",
    "for train_index, test_index in rskf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    splits.append( (X_train, X_test, y_train, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**common parameters and results initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 1000\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict.fromkeys([\"MY\", \"RF\", \"ADA\"], None)\n",
    "\n",
    "def dump_result(model_nm, model, split_num, X_test, results = results):\n",
    "    \"\"\"\n",
    "    model_nm can be \"MY\", \"RF\" or \"ADA\"\n",
    "    \"\"\"\n",
    "    if results[model_nm] is None:\n",
    "        results[model_nm] = {}\n",
    "    d = {}\n",
    "    d['labels'] = model.predict(X_test)\n",
    "    d['proba'] = model.predict_proba(X_test)\n",
    "    d['probs'] = warm_predict(model, X_test, proba = True)\n",
    "    results[model_nm][split_num] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MyEnsemle fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "    my = MyEnsemble.MyEnsemble(num_classes = num_classes, reg_param = 1.1, lr = 1.0,\\\n",
    "                           num_trees = num_trees, warm_start = False, max_depth = 10,\\\n",
    "                           verbose = 1, bootstrap_seed = 42)\n",
    "    my.fit(X_train, y_train)\n",
    "    fpt(my, X_test, y_test)\n",
    "    dump_result(\"MY\", my, i, X_test)\n",
    "    print(\">\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "    rf = RandomForestClassifier(n_estimators = num_trees, criterion = 'entropy', random_state = 42,\\\n",
    "                                bootstrap = True, max_features = 'sqrt')\n",
    "    rf.fit(X_train, y_train)\n",
    "    fpt(rf, X_test, y_test)\n",
    "    dump_result(\"RF\", rf, i, X_test)\n",
    "    print(\">\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoost fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "    dc = DecisionTreeClassifier(criterion='entropy', max_depth = 10)\n",
    "    ada = AdaBoostClassifier(n_estimators = num_trees, random_state = 42, learning_rate = 1.2,\\\n",
    "                             base_estimator = dc)\n",
    "    ada.fit(X_train, y_train)\n",
    "    fpt(ada, X_test, y_test)\n",
    "    dump_result(\"ADA\", ada, i, X_test)\n",
    "    print(\">\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**illustrations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAMME_R(p):\n",
    "    \"\"\"\n",
    "    p.shape = (Est_num, X_num, Class_num)\n",
    "    \"\"\"\n",
    "    K = p.shape[-1]\n",
    "    np.clip(p, np.finfo(p.dtype).eps, None, out = p)\n",
    "    log_p = np.log(p)\n",
    "    H = (K - 1)*( log_p - log_p.mean(axis = 2)[:, :, np.newaxis] )\n",
    "    return np.array(H) #(Est_num, X_num, Class_num)\n",
    "\n",
    "\n",
    "def _inn_res(y, cum_p, auc = False):\n",
    "    res = []\n",
    "    for i in range(cum_p.shape[0]):\n",
    "        if auc:\n",
    "            res.append(roc_auc_score(y, cum_p[i, :, 1]))\n",
    "        else:\n",
    "            my = cum_p[i, :, :].argmax(-1)\n",
    "            res.append(accuracy_score(y, my))\n",
    "    return np.array(res)\n",
    "\n",
    "        \n",
    "def get_both_showres(y, p1, p2,  est_cnt, auc = False, sammer = False):\n",
    "    \"\"\"\n",
    "    p.shape = (Est_num, X_num, Class_num)\n",
    "    \"\"\"\n",
    "    if sammer:\n",
    "        p1 = SAMME_R(p1)\n",
    "        p2 = SAMME_R(p2)\n",
    "    rp = np.zeros((est_cnt, p1.shape[1], p1.shape[2]))\n",
    "    for i in range(est_cnt): #ms\n",
    "        s1, s2 = p1[:i+1].shape[0], p2[:i+1].shape[0]\n",
    "        rp[i] = (p1[:i+1].sum(0)+p2[:i+1].sum(0)) / (s1 + s2)\n",
    "    return _inn_res(y, rp, auc) # (Est_num, X_num, Class_num)\n",
    "\n",
    "\n",
    "def get_showres(y, p, est_cnt, auc = False, sammer = False):\n",
    "    \"\"\"\n",
    "    p.shape = (Est_num, X_num, Class_num)\n",
    "    \"\"\"\n",
    "    rp = np.zeros((est_cnt, p.shape[1], p.shape[2]))\n",
    "    if sammer:\n",
    "        p = SAMME_R(p)\n",
    "    for i in range(est_cnt):\n",
    "        rp[i] = p[:i+1].mean(0) \n",
    "    return _inn_res(y, rp, auc) # (Est_num, X_num, Class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_d_auc = dict.fromkeys([\"MY\", \"RF\", \"ADA\"])\n",
    "q_d_bauc = dict.fromkeys([\"MY with RF\", \"MY with ADA\"])\n",
    "\n",
    "for el in [q_d_auc, q_d_bauc]:\n",
    "    for k in el.keys():\n",
    "        el[k] = []\n",
    "\n",
    "for i, (_, _, _, y_test) in tqdm(enumerate(splits), total = len(splits)):\n",
    "    # one auc\n",
    "    for nm in [\"MY\", \"RF\", \"ADA\"]:\n",
    "        r = get_showres(y = y_test, p = results[nm][i]['probs'], est_cnt=num_trees,\\\n",
    "                        auc = True, sammer = nm == \"ADA\")\n",
    "        q_d_auc[nm].append(r)\n",
    "\n",
    "    # both auc\n",
    "    for nm in [\"RF\", \"ADA\"]:\n",
    "        r = get_both_showres(y = y_test, p1 = results[\"MY\"][i]['probs'], p2 = results[nm][i]['probs'],\\\n",
    "                             est_cnt = num_trees, auc = True)\n",
    "        q_d_bauc[\"MY with \"+nm].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_d_acc = dict.fromkeys([\"MY\", \"RF\", \"ADA\"])\n",
    "q_d_bacc = dict.fromkeys([\"MY with RF\", \"MY with ADA\"])\n",
    "\n",
    "for el in [q_d_acc, q_d_bacc]:\n",
    "    for k in el.keys():\n",
    "        el[k] = []\n",
    "\n",
    "for i, (_, _, _, y_test) in tqdm(enumerate(splits), total = len(splits)):\n",
    "    # one acc\n",
    "    for nm in [\"MY\", \"RF\", \"ADA\"]:\n",
    "        r = get_showres(y = y_test, p = results[nm][i]['probs'], est_cnt=num_trees,\\\n",
    "                        auc = False, sammer = nm == \"ADA\")\n",
    "        q_d_acc[nm].append(r)\n",
    "\n",
    "    # both acc\n",
    "    for nm in [\"RF\", \"ADA\"]:\n",
    "        r = get_both_showres(y = y_test, p1 = results[\"MY\"][i]['probs'], p2 = results[nm][i]['probs'],\\\n",
    "                             est_cnt = num_trees, auc = False)\n",
    "        q_d_bacc[\"MY with \"+nm].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_l_acc = []\n",
    "for k in [\"MY\", \"RF\", \"ADA\"]:\n",
    "    q_l_acc.append( (np.array(q_d_acc[k]).mean(0), k))\n",
    "\n",
    "q_l_bacc = []\n",
    "for k in [\"MY with RF\", \"MY with ADA\"]:\n",
    "    q_l_bacc.append( (np.array(q_d_bacc[k]).mean(0), k))\n",
    "\n",
    "q_l_auc = []\n",
    "for k in [\"MY\", \"RF\", \"ADA\"]:\n",
    "    q_l_auc.append( (np.array(q_d_auc[k]).mean(0), k))\n",
    "\n",
    "q_l_bauc = []\n",
    "for k in [\"MY with RF\", \"MY with ADA\"]:\n",
    "    q_l_bauc.append( (np.array(q_d_bauc[k]).mean(0), k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_show(spec_l, step, indent,\\\n",
    "              yticks, y_nm, x_nm, colors = ['r','g','b','c--','m','y','k']):\n",
    "    \"\"\"\n",
    "    spec_l = list[(q_l, nm)]\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(spec_l) > len(colors):\n",
    "        print(\"WRONG LEN\")\n",
    "        return -1\n",
    "    \n",
    "    f, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(10, 7.5))\n",
    "    for i, (q_l, lab) in enumerate(spec_l):\n",
    "        nm = lab\n",
    "        if 'MY' in lab:\n",
    "            nm = nm.replace(\"MY\", 'Algorithm')\n",
    "        tmp = q_l[-indent:]\n",
    "        st = len(q_l) - indent + 1\n",
    "        c = colors[i]\n",
    "        ax1.plot(range(st, len(q_l)+1) , tmp*100, c, label = nm, linewidth = 1.5)\n",
    "        ax1.set_xticks([st+i for i in range(0, len(tmp), step)] +[len(q_l),])\n",
    "    \n",
    "    ax1.set_yticks(yticks*100)\n",
    "    ax1.grid()\n",
    "    ax1.set_xlabel(x_nm, fontsize=16)\n",
    "    ax1.set_ylabel(y_nm, fontsize=16)\n",
    "    ax1.legend()\n",
    "    \n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AX1_step, AX2_step, AX2_indent = 100, 200, 951"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks1 = np.linspace(0.66, 0.773, 21)\n",
    "yticks2 = np.linspace(0.75, 0.773, 10)\n",
    "\n",
    "yticks = yticks1\n",
    "\n",
    "spec_show(spec_l = q_l_acc + q_l_bacc,\\\n",
    "     step = AX1_step, indent = 1000, yticks = yticks,\\\n",
    "     y_nm = 'accuracy', x_nm = 'estimators number', colors = [ 'r', 'g', 'b','c--', 'k--'])\n",
    "\n",
    "yticks = yticks2\n",
    "\n",
    "spec_show(spec_l = q_l_acc,\\\n",
    "     step = AX2_step, indent = AX2_indent, yticks = yticks,\\\n",
    "     y_nm = 'acc', x_nm = 'estimators number', colors = [ 'r', 'g', 'b','c--', 'k--'])\n",
    "\n",
    "# ADA + MY\n",
    "\n",
    "yticks = yticks2\n",
    "\n",
    "spec_show(spec_l = q_l_acc + q_l_bacc[1:],\\\n",
    "     step = AX2_step, indent = AX2_indent, yticks = yticks,\\\n",
    "     y_nm = 'accuracy', x_nm = 'estimators number', colors = [ 'r', 'g', 'b','k--'])\n",
    "\n",
    "# MY + RF\n",
    "\n",
    "yticks = yticks2\n",
    "\n",
    "spec_show(spec_l = q_l_acc + q_l_bacc[:1],\\\n",
    "     step = AX2_step, indent = AX2_indent, yticks = yticks,\\\n",
    "     y_nm = 'accuracy', x_nm = 'estimators number', colors = [ 'r', 'g', 'b','c--', 'k--'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks1 = np.linspace(0.59, 0.8, 21)\n",
    "yticks2 = np.linspace(0.76, 0.792, 10)\n",
    "\n",
    "yticks = yticks1\n",
    "\n",
    "spec_show(spec_l = q_l_auc + q_l_bauc,\\\n",
    "     step = AX1_step, indent = 1000, yticks = yticks,\\\n",
    "     y_nm = 'auc', x_nm = 'estimators number', colors = [ 'r', 'g', 'b', 'c--', 'k--'])\n",
    "\n",
    "yticks = yticks2\n",
    "\n",
    "spec_show(spec_l = q_l_auc,\\\n",
    "     step = AX2_step, indent = AX2_indent, yticks = yticks,\\\n",
    "     y_nm = 'auc', x_nm = 'estimators number', colors = [ 'r', 'g', 'b', 'c--', 'k--'])\n",
    "\n",
    "# ADA + MY\n",
    "\n",
    "yticks = yticks2\n",
    "\n",
    "spec_show(spec_l = q_l_auc + q_l_bauc[1:],\\\n",
    "     step = AX2_step, indent = AX2_indent, yticks = yticks,\\\n",
    "     y_nm = 'auc', x_nm = 'estimators number', colors = [ 'r', 'g', 'b', 'k--'])\n",
    "\n",
    "# MY + RF\n",
    "\n",
    "yticks = yticks2\n",
    "\n",
    "spec_show(spec_l = q_l_auc + q_l_bauc[:1],\\\n",
    "     step = AX2_step, indent = AX2_indent, yticks = yticks,\\\n",
    "     y_nm = 'auc', x_nm = 'estimators number', colors = [ 'r', 'g', 'b', 'c--', 'k--'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
